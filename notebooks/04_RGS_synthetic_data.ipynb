{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from RGS import FastRandomizedGreedySelection, RandomizedGreedySelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_datasets(data):\n",
    "    \"\"\"\n",
    "    Clean datasets by removing missing values and duplicate rows.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : dict\n",
    "        Dictionary containing pandas DataFrames for each dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing cleaned DataFrames\n",
    "    \"\"\"\n",
    "    cleaned_data = {}\n",
    "    \n",
    "    for label, df in data.items():\n",
    "        print(f\"\\nCleaning dataset: {label}\")\n",
    "        print(f\"Original shape: {df.shape}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_before = df.isnull().sum().sum()\n",
    "        print(f\"Missing values before: {missing_before}\")\n",
    "        \n",
    "        # Check for duplicates\n",
    "        duplicates_before = df.duplicated().sum()\n",
    "        print(f\"Duplicate rows before: {duplicates_before}\")\n",
    "        \n",
    "        # Remove missing values\n",
    "        df_cleaned = df.dropna()\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df_cleaned = df_cleaned.drop_duplicates()\n",
    "        \n",
    "        # Final checks\n",
    "        missing_after = df_cleaned.isnull().sum().sum()\n",
    "        duplicates_after = df_cleaned.duplicated().sum()\n",
    "        \n",
    "        print(f\"Final shape: {df_cleaned.shape}\")\n",
    "        print(f\"Rows removed due to missing values: {len(df) - len(df_cleaned)}\")\n",
    "        print(f\"Missing values after: {missing_after}\")\n",
    "        print(f\"Duplicate rows after: {duplicates_after}\")\n",
    "        \n",
    "        cleaned_data[label] = df_cleaned\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_observations(df, n_samples=5000):\n",
    "    \"\"\"\n",
    "    Generate synthetic observations based on the covariance structure of features\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame with original data\n",
    "    n_samples: number of synthetic samples to generate\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with synthetic observations\n",
    "    \"\"\"\n",
    "    # Separate features from target\n",
    "    X = df.drop('target', axis=1)\n",
    "    \n",
    "    # Calculate mean vector and covariance matrix\n",
    "    mean_vector = np.mean(X, axis=0)\n",
    "    cov_matrix = np.cov(X.values.T)\n",
    "    \n",
    "    # Generate random samples from multivariate normal distribution\n",
    "    synthetic_samples = np.random.multivariate_normal(\n",
    "        mean=mean_vector,\n",
    "        cov=cov_matrix,\n",
    "        size=n_samples\n",
    "    )\n",
    "    \n",
    "    # Convert to DataFrame with original feature names\n",
    "    synthetic_df = pd.DataFrame(synthetic_samples, columns=X.columns)\n",
    "    \n",
    "    return synthetic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Auto Pricing', 'Bodyfat', 'Sunspots', 'Pharynx', 'PW', 'CPU', 'House', 'MeatFat']\n",
    "data = {}\n",
    "\n",
    "# Load data\n",
    "data['Auto Pricing'] = pd.read_csv('../real_data/207_autoPrice.tsv', sep='\\t')\n",
    "data['Sunspots'] = pd.read_csv('../real_data/695_chatfield_4.tsv', sep='\\t')\n",
    "data['Bodyfat'] = pd.read_csv('../real_data/560_bodyfat.tsv', sep='\\t')\n",
    "data['Pharynx'] = pd.read_csv('../real_data/1196_BNG_pharynx.tsv', sep='\\t')\n",
    "data['PW'] = pd.read_csv('../real_data/229_pwLinear.tsv', sep='\\t')\n",
    "data['CPU'] = pd.read_csv('../real_data/197_cpu_act.tsv', sep='\\t')\n",
    "data['House'] = pd.read_csv('../real_data/574_house_16H.tsv', sep='\\t')\n",
    "data['MeatFat'] = pd.read_csv('../real_data/505_tecator.tsv', sep='\\t')\n",
    "\n",
    "# Clean the datasets\n",
    "cleaned_data = clean_datasets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "syn_data = {}\n",
    "\n",
    "for label in labels:\n",
    "    syn_data[label] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read TSV data\n",
    "df = pd.read_csv('your_file.tsv', sep='\\t')\n",
    "\n",
    "# Convert to numpy array and compute covariance\n",
    "data = df.values\n",
    "covariance_matrix = np.cov(data.T)  # .T transposes the data as np.cov expects variables as rows\n",
    "\n",
    "# Print matrix dimensions\n",
    "print(f\"\\nCovariance matrix shape: {covariance_matrix.shape}\")\n",
    "\n",
    "# Print the covariance matrix with variable names\n",
    "print(\"\\nCovariance matrix:\")\n",
    "print(pd.DataFrame(covariance_matrix, columns=df.columns, index=df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n, p = 500, 500 # 5000 samples, 500 features\n",
    "\n",
    "# Create base features\n",
    "X = np.random.randn(n, p)\n",
    "\n",
    "# Introduce correlations\n",
    "A = np.eye(p) + 0.2 * np.ones((p, p))\n",
    "X = X @ A\n",
    "\n",
    "# Create true coefficients (some zero, some non-zero)\n",
    "true_coef = np.zeros(p)\n",
    "true_coef[:6] = [1.5, 0.8, 1.2, 0.5, 0.7, 0.05]  # Only first 6 features are relevant\n",
    "\n",
    "# Create the target variable (linear model)\n",
    "sigma = 1\n",
    "y = X @ true_coef + sigma * np.random.normal(0, 1, n)  # Add some noise\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgs1 = FastRandomizedGreedySelection(k_max=15, m=200)\n",
    "rgs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgs2 = FastRandomizedGreedySelection(k_max=15, m=200, n_resample_iter=1)\n",
    "rgs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgs3 = FastRandomizedGreedySelection(k_max=15, m=200, n_resample_iter=2)\n",
    "rgs3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012463106871794572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgs1</th>\n",
       "      <th>rgs2</th>\n",
       "      <th>rgs3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>457.946755</td>\n",
       "      <td>457.946755</td>\n",
       "      <td>457.946755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.958522</td>\n",
       "      <td>1.128858</td>\n",
       "      <td>1.191185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.292462</td>\n",
       "      <td>0.272517</td>\n",
       "      <td>0.406167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125505</td>\n",
       "      <td>0.151693</td>\n",
       "      <td>0.186742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.072272</td>\n",
       "      <td>0.064924</td>\n",
       "      <td>0.077382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041882</td>\n",
       "      <td>0.041343</td>\n",
       "      <td>0.047635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>0.031133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>0.021527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.011942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007404</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>0.008140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.006873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.006425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>0.009582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010807</td>\n",
       "      <td>0.010718</td>\n",
       "      <td>0.010942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rgs1        rgs2        rgs3\n",
       "0   457.946755  457.946755  457.946755\n",
       "1     0.958522    1.128858    1.191185\n",
       "2     0.292462    0.272517    0.406167\n",
       "3     0.125505    0.151693    0.186742\n",
       "4     0.072272    0.064924    0.077382\n",
       "5     0.041882    0.041343    0.047635\n",
       "6     0.024652    0.022743    0.031133\n",
       "7     0.016293    0.013587    0.021527\n",
       "8     0.010693    0.009187    0.011942\n",
       "9     0.007404    0.007755    0.008140\n",
       "10    0.006517    0.006388    0.006873\n",
       "11    0.006485    0.006453    0.006425\n",
       "12    0.007106    0.006962    0.007014\n",
       "13    0.008028    0.008040    0.008174\n",
       "14    0.009284    0.009242    0.009582\n",
       "15    0.010807    0.010718    0.010942"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = {\"rgs1\" : rgs1,\n",
    "              \"rgs2\" : rgs2,\n",
    "              \"rgs3\" : rgs3}\n",
    "results = {}\n",
    "for name, estimator in estimators.items():\n",
    "    results[name] = [mean_squared_error(estimator.predict(X_test, k), X_test @ true_coef) for k in range(0, 16)]\n",
    "print(mean_squared_error(lasso.predict(X_test), X_test @ true_coef))\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability_scores = {}\n",
    "# for name, estimator in estimators.items():\n",
    "#     stability_scores[name] = estimator.fit_stability()\n",
    "# pd.DataFrame(stability_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   1,   4,   3, 342, 205, 375, 318, 252,   5, 366, 244,\n",
       "       444, 452, 338, 219, 391, 371, 326, 420, 272, 359,  77, 197, 107,\n",
       "       424, 185, 489, 380, 291,  95, 163, 300, 405, 259, 279, 480, 422,\n",
       "       157, 165, 167, 170, 156, 159, 158, 168, 169, 160, 161, 164, 166,\n",
       "       162, 150, 155, 154, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
       "       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 172, 149, 129,\n",
       "       151, 152, 153, 171, 180, 173, 221, 208, 209, 210, 211, 212, 213,\n",
       "       214, 215, 216, 217, 218, 220, 222, 206, 223, 224, 225, 226, 227,\n",
       "       228, 229, 230, 231, 232, 233, 234, 207, 204, 174, 188, 175, 176,\n",
       "       177, 178, 179, 127, 181, 182, 183, 184, 186, 187, 189, 203, 190,\n",
       "       191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 128, 118,\n",
       "       126,  48,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
       "        47,  49,  34,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,\n",
       "        60,  61,  35,  33,  63,  18,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  19,  32,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  62,  64, 125, 111,  98,  99, 100,\n",
       "       101, 102, 103, 104, 105, 106, 108, 109, 110, 112,  96, 113, 114,\n",
       "       115, 116, 117, 236, 119, 120, 121, 122, 123, 124,  97,  94,  65,\n",
       "        79,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  78,\n",
       "        80,  93,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92, 235, 499, 237, 418, 406, 407, 408, 409, 410, 411, 412, 413,\n",
       "       414, 415, 416, 417, 419, 403, 421, 423, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 404, 402, 369, 386, 372, 373, 374, 376,\n",
       "       377, 378, 379, 381, 382, 383, 384, 385, 387, 401, 388, 389, 390,\n",
       "       392, 393, 394, 395, 396, 397, 398, 399, 400, 435, 436, 437, 483,\n",
       "       470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, 484,\n",
       "       438, 485, 486, 487, 488, 490, 491, 492, 493, 494, 495, 496, 497,\n",
       "       469, 468, 467, 466, 439, 440, 441, 442, 443, 445, 446, 447, 448,\n",
       "       449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
       "       463, 464, 465, 370, 368, 238, 286, 273, 274, 275, 276, 277, 278,\n",
       "       280, 281, 282, 283, 284, 285, 287, 270, 288, 289, 290, 292, 293,\n",
       "       294, 295, 296, 297, 298, 299, 301, 271, 269, 367, 253, 239, 240,\n",
       "       241, 242, 243, 245, 246, 247, 248, 498, 250, 251, 254, 268, 255,\n",
       "       256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 302, 303,\n",
       "       304, 351, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349,\n",
       "       350, 352, 305, 353, 354, 355, 356, 357, 358, 360, 361, 362, 363,\n",
       "       364, 365, 336, 335, 334, 333, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 324, 325, 327,\n",
       "       328, 329, 330, 331, 332, 249])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(lasso.coef_).argsort()[::-1] # Feature 5 only shows up in 11th place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   1,   4,   3,   5, 252, 241, 342, 452,  77, 423, 429,\n",
       "       163, 375, 386, 170,  32, 434, 109,  53, 424, 116, 195, 418, 469,\n",
       "       391,  60,  41, 498, 266, 179, 472, 444, 318, 185, 384, 439, 455,\n",
       "       413,  55, 349, 405, 317, 487, 358, 420, 306, 387, 229, 347, 205,\n",
       "       339, 265,  34, 194, 443, 181,  62,  25, 214, 218, 380, 432, 154,\n",
       "       321, 126,  61,  63, 490, 260, 451, 106, 488,  85, 284,  95, 422,\n",
       "       271, 426,  30, 366,  79, 122, 259, 201, 150, 192, 401, 332, 244,\n",
       "       249,  84, 393,  59,  45, 335, 468, 153, 343, 107, 171, 354, 145,\n",
       "       118, 296, 491, 368, 279, 234, 398, 378, 280, 143, 489, 136, 135,\n",
       "       134, 130, 133, 137, 138, 139, 140, 132, 141, 142, 131, 407, 125,\n",
       "       129, 114, 104, 105, 474, 108, 473, 110, 111, 112, 113, 115, 128,\n",
       "       471, 117, 119, 120, 121, 470, 123, 124, 127, 144, 151, 146, 147,\n",
       "       175, 176, 177, 178, 463, 180, 462, 182, 183, 184, 461, 186, 187,\n",
       "       188, 189, 190, 191, 460, 193, 459, 458, 174, 173, 172, 159, 148,\n",
       "       149, 467, 152, 466, 155, 156, 157, 158, 160, 464, 161, 162, 465,\n",
       "       164, 165, 166, 167, 168, 169, 103,  96, 102,  24,  26,  27,  28,\n",
       "        29,  31,  33, 486,  35,  36,  37,  38,  39,  40, 485,  42,  43,\n",
       "        44,  46,  47,  48,  49, 492,  23, 101,  22, 497, 496, 495, 494,\n",
       "       493,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,\n",
       "        18,  19,  20,  21,  50,  51,  52, 484, 477,  80,  81,  82,  83,\n",
       "       476,  86,  87,  88,  89,  90,  91,  92,  93,  94, 475, 197,  97,\n",
       "        98,  99, 100,  78, 478,  76,  64,  54, 483,  56,  57,  58, 482,\n",
       "       481, 480, 479,  65,  75,  66,  67,  68,  69,  70,  71,  72,  73,\n",
       "        74, 196, 203, 198, 326, 328, 329, 330, 331, 430, 333, 334, 336,\n",
       "       337, 338, 428, 340, 341, 427, 344, 345, 346, 425, 348, 421, 350,\n",
       "       327, 325, 352, 324, 303, 304, 305, 436, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 435, 433, 319, 320, 431, 322, 323, 351,\n",
       "       353, 199, 381, 383, 414, 385, 412, 411, 388, 389, 390, 410, 392,\n",
       "       394, 395, 396, 397, 399, 400, 409, 402, 403, 404, 408, 382, 415,\n",
       "       355, 379, 356, 357, 419, 359, 360, 361, 362, 363, 364, 365, 417,\n",
       "       367, 369, 370, 371, 372, 373, 374, 416, 376, 377, 302, 301, 300,\n",
       "       223, 225, 226, 227, 228, 450, 230, 231, 232, 233, 235, 236, 237,\n",
       "       238, 239, 240, 449, 242, 243, 448, 245, 246, 224, 222, 299, 221,\n",
       "       200, 457, 202, 406, 204, 456, 206, 207, 208, 209, 210, 211, 212,\n",
       "       213, 454, 215, 216, 217, 453, 219, 220, 247, 248, 447, 250, 275,\n",
       "       276, 277, 278, 281, 282, 283, 437, 285, 286, 287, 288, 289, 290,\n",
       "       291, 292, 293, 294, 295, 297, 298, 274, 273, 272, 442, 251, 446,\n",
       "       253, 254, 255, 256, 257, 258, 445, 261, 438, 262, 263, 264, 441,\n",
       "       440, 267, 268, 269, 270, 499])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(rgs1.coef_[5]).argsort()[::-1] # Feature 5 shows up in 6th place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   1,   4,   3, 342, 375,   5, 205, 249, 273, 452,  10,\n",
       "       444, 252,  77, 109, 163, 391, 424, 318,  32, 355, 107, 185, 116,\n",
       "       380, 241, 423, 429, 170, 146,  41, 405, 498, 418, 443, 259,  60,\n",
       "       195,  44, 145, 422, 472, 439,  62, 386, 420, 434, 455, 384, 360,\n",
       "       469, 387,  34,  95, 349, 359, 266, 179, 343, 244, 265, 490,  61,\n",
       "        55, 378, 321, 413,  53, 317, 181, 194, 121,  25, 218, 426, 260,\n",
       "       214, 366,  84, 306, 198, 143, 332, 118, 293,  85,  30, 487, 393,\n",
       "       347, 371, 197, 489, 192, 229, 319, 451, 379, 154, 432,  45,  26,\n",
       "       340,  82, 416, 280, 368, 171, 488, 494, 126, 219, 401, 326, 271,\n",
       "        79, 106, 358,  59, 279, 363,  63, 296, 339, 284, 479, 122, 491,\n",
       "       234, 335, 468, 459, 150, 161, 153, 201, 354, 398, 135, 130, 136,\n",
       "       132, 131, 105, 108, 133, 134, 104, 119, 467, 114, 117, 120, 464,\n",
       "       466, 137, 115, 123, 124, 110, 125, 113, 127, 112, 111, 128, 465,\n",
       "       129, 461, 138, 177, 167, 168, 169, 172, 173, 174, 175, 176, 178,\n",
       "       165, 458, 180, 457, 182, 183, 184, 456, 186, 166, 164, 139, 149,\n",
       "       140, 141, 142, 463, 144, 462, 147, 148, 151, 460, 152, 155, 156,\n",
       "       157, 158, 159, 160, 162, 103, 404, 102, 101,  27,  28,  29, 484,\n",
       "        31, 483,  33, 482,  35,  36,  37,  38,  39,  40, 481,  42,  43,\n",
       "       480,  46,  47,  48, 485,  24,  23,  11, 497, 496, 495, 493,   6,\n",
       "         7,   8,   9, 486,  12,  22,  13,  14,  15,  16,  17,  18,  19,\n",
       "        20,  21,  49,  50,  51,  91,  81,  83, 473, 471,  86,  87,  88,\n",
       "        89,  90, 188,  78,  92,  93,  94, 470,  96,  97,  98,  99, 100,\n",
       "        80, 474,  52,  65,  54, 478,  56,  57,  58, 477, 476, 475,  64,\n",
       "        66,  76,  67,  68,  69,  70,  71,  72,  73,  74,  75, 187, 202,\n",
       "       189, 333, 323, 324, 325, 327, 328, 329, 330, 331, 430, 334, 431,\n",
       "       336, 337, 338, 341, 428, 344, 345, 346, 427, 322, 320, 190, 435,\n",
       "       297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 433, 308, 309,\n",
       "       310, 311, 312, 313, 314, 315, 316, 348, 425, 350, 390, 381, 382,\n",
       "       383, 410, 385, 409, 408, 388, 389, 407, 351, 392, 406, 394, 395,\n",
       "       396, 397, 399, 400, 402, 411, 412, 377, 376, 352, 353, 421, 356,\n",
       "       357, 419, 417, 361, 362, 364, 365, 367, 369, 370, 415, 372, 373,\n",
       "       374, 414, 295, 294, 436, 227, 217, 448, 220, 221, 222, 223, 224,\n",
       "       225, 226, 228, 447, 230, 231, 232, 233, 235, 236, 237, 238, 239,\n",
       "       216, 215, 449, 213, 191, 193, 454, 453, 196, 450, 199, 200, 403,\n",
       "       203, 204, 492, 206, 207, 208, 209, 210, 211, 212, 240, 242, 292,\n",
       "       278, 268, 269, 270, 272, 437, 274, 275, 276, 277, 281, 243, 282,\n",
       "       283, 285, 286, 287, 288, 289, 290, 291, 267, 438, 440, 264, 245,\n",
       "       246, 247, 248, 446, 250, 251, 445, 253, 254, 255, 256, 257, 258,\n",
       "       442, 441, 261, 262, 263, 499])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(rgs1.coef_[10]).argsort()[::-1] # Feature 5 shows up in 8th place"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
