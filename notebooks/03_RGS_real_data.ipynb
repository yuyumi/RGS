{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from RGS import FastRandomizedGreedySelection, RandomizedGreedySelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_datasets(data):\n",
    "    \"\"\"\n",
    "    Clean datasets by removing missing values and duplicate rows.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : dict\n",
    "        Dictionary containing pandas DataFrames for each dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing cleaned DataFrames\n",
    "    \"\"\"\n",
    "    cleaned_data = {}\n",
    "    \n",
    "    for label, df in data.items():\n",
    "        print(f\"\\nCleaning dataset: {label}\")\n",
    "        print(f\"Original shape: {df.shape}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_before = df.isnull().sum().sum()\n",
    "        print(f\"Missing values before: {missing_before}\")\n",
    "        \n",
    "        # Check for duplicates\n",
    "        duplicates_before = df.duplicated().sum()\n",
    "        print(f\"Duplicate rows before: {duplicates_before}\")\n",
    "        \n",
    "        # Remove missing values\n",
    "        df_cleaned = df.dropna()\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df_cleaned = df_cleaned.drop_duplicates()\n",
    "        \n",
    "        # Final checks\n",
    "        missing_after = df_cleaned.isnull().sum().sum()\n",
    "        duplicates_after = df_cleaned.duplicated().sum()\n",
    "        \n",
    "        print(f\"Final shape: {df_cleaned.shape}\")\n",
    "        print(f\"Rows removed due to missing values: {len(df) - len(df_cleaned)}\")\n",
    "        print(f\"Missing values after: {missing_after}\")\n",
    "        print(f\"Duplicate rows after: {duplicates_after}\")\n",
    "        \n",
    "        cleaned_data[label] = df_cleaned\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_splits(Xs, ys, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Create train/test splits for multiple datasets stored in dictionaries.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Xs : dict\n",
    "        Dictionary containing feature matrices for each dataset\n",
    "    ys : dict\n",
    "        Dictionary containing target variables for each dataset\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of the dataset to include in the test split\n",
    "    random_state : int, default=42\n",
    "        Random state for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing X_train, X_test, y_train, y_test for each dataset\n",
    "    \"\"\"\n",
    "    splits = {}\n",
    "    \n",
    "    for label in Xs.keys():\n",
    "        X = Xs[label]\n",
    "        y = ys[label]\n",
    "        \n",
    "        # Create train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            shuffle=True,\n",
    "            stratify=y if len(np.unique(y)) < 10 else None  # Stratify only for classification tasks\n",
    "        )\n",
    "        \n",
    "        # Store splits in dictionary\n",
    "        splits[label] = {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'train_size': len(X_train),\n",
    "            'test_size': len(X_test)\n",
    "        }\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "def train_regularized_models(splits, cv=5):\n",
    "    \"\"\"\n",
    "    Train and evaluate Lasso, Ridge, and ElasticNet models on multiple datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    splits : dict\n",
    "        Dictionary containing train/test splits for each dataset\n",
    "    cv : int, default=5\n",
    "        Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing trained models, predictions, and performance metrics\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Define parameter grids for each model\n",
    "    param_grids = {\n",
    "        'Lasso': {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "        'Ridge': {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "        'ElasticNet': {\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "            'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Lasso': Lasso(random_state=42, max_iter=10000),\n",
    "        'Ridge': Ridge(random_state=42),\n",
    "        'ElasticNet': ElasticNet(random_state=42, max_iter=10000)\n",
    "    }\n",
    "    \n",
    "    for dataset_name in splits:\n",
    "        print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "        results[dataset_name] = {}\n",
    "        \n",
    "        # Get train/test data\n",
    "        X_train = splits[dataset_name]['X_train']\n",
    "        X_test = splits[dataset_name]['X_test']\n",
    "        y_train = splits[dataset_name]['y_train']\n",
    "        y_test = splits[dataset_name]['y_test']\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Train and evaluate each model\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"\\nTraining {model_name}...\")\n",
    "            \n",
    "            # Perform grid search with cross-validation\n",
    "            grid_search = GridSearchCV(\n",
    "                model,\n",
    "                param_grids[model_name],\n",
    "                cv=cv,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Get best model\n",
    "            best_model = grid_search.best_estimator_\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred_train = best_model.predict(X_train_scaled)\n",
    "            y_pred_test = best_model.predict(X_test_scaled)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "                'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "                'train_r2': r2_score(y_train, y_pred_train),\n",
    "                'test_r2': r2_score(y_test, y_pred_test),\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'cv_results': grid_search.cv_results_\n",
    "            }\n",
    "            \n",
    "            # Store results\n",
    "            results[dataset_name][model_name] = {\n",
    "                'model': best_model,\n",
    "                'predictions': {\n",
    "                    'train': y_pred_train,\n",
    "                    'test': y_pred_test\n",
    "                },\n",
    "                'metrics': metrics\n",
    "            }\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Best parameters: {metrics['best_params']}\")\n",
    "            print(f\"Train RMSE: {metrics['train_rmse']:.4f}\")\n",
    "            print(f\"Test RMSE: {metrics['test_rmse']:.4f}\")\n",
    "            print(f\"Train R²: {metrics['train_r2']:.4f}\")\n",
    "            print(f\"Test R²: {metrics['test_r2']:.4f}\")\n",
    "            \n",
    "            # Print feature importance for Lasso and ElasticNet\n",
    "            if model_name in ['Lasso', 'ElasticNet']:\n",
    "                feature_importance = pd.DataFrame({\n",
    "                    'Feature': [f\"Feature_{i}\" for i in range(X_train.shape[1])],\n",
    "                    'Coefficient': best_model.coef_\n",
    "                })\n",
    "                feature_importance = feature_importance[feature_importance['Coefficient'] != 0]\n",
    "                print(\"\\nNon-zero coefficients:\")\n",
    "                print(feature_importance.sort_values(by='Coefficient', key=abs, ascending=False))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def tune_rgs_parameters(X_train, y_train, X_test, y_test, cv=5):\n",
    "    \"\"\"\n",
    "    Tune both 'm' and 'k_max' parameters for FastRandomizedGreedySelection using cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : array-like\n",
    "        Training features\n",
    "    y_train : array-like\n",
    "        Training target\n",
    "    X_test : array-like\n",
    "        Test features\n",
    "    y_test : array-like\n",
    "        Test target\n",
    "    cv : int, default=5\n",
    "        Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing results and best model\n",
    "    \"\"\"\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    # Generate values for m and k_max\n",
    "    m_values = [int(m) for m in np.unique(np.linspace(1, n_features, 10, dtype=int))]\n",
    "    k_max_values = [int(k) for k in np.unique(np.linspace(2, n_features, 10, dtype=int))]\n",
    "    \n",
    "    # Verify types\n",
    "    assert all(isinstance(m, int) for m in m_values), \"All m values must be Python integers\"\n",
    "    assert all(isinstance(k, int) for k in k_max_values), \"All k_max values must be Python integers\"\n",
    "    \n",
    "    # Store results\n",
    "    cv_results = []\n",
    "    \n",
    "    print(\"Tuning parameters...\")\n",
    "    print(f\"Testing m values: {m_values}\")\n",
    "    print(f\"Testing k_max values: {k_max_values}\")\n",
    "    \n",
    "    # Grid search over both parameters\n",
    "    for k_max in k_max_values:\n",
    "        for m in m_values:\n",
    "            assert isinstance(m, int) and isinstance(k_max, int)\n",
    "            \n",
    "            # Skip invalid combinations where m < k_max\n",
    "            if m < k_max:\n",
    "                continue\n",
    "                \n",
    "            rgs = FastRandomizedGreedySelection(k_max=k_max, m=m)\n",
    "            scores = cross_val_score(rgs, X_train, y_train, cv=cv, scoring='r2')\n",
    "            mean_score = np.mean(scores)\n",
    "            std_score = np.std(scores)\n",
    "            \n",
    "            cv_results.append({\n",
    "                'm': m,\n",
    "                'k_max': k_max,\n",
    "                'mean_cv_score': mean_score,\n",
    "                'std_cv_score': std_score\n",
    "            })\n",
    "            \n",
    "#             print(f\"k_max={k_max}, m={m}: CV R² = {mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "    \n",
    "    # Find best parameters\n",
    "    best_result = max(cv_results, key=lambda x: x['mean_cv_score'])\n",
    "    best_m = best_result['m']\n",
    "    best_k_max = best_result['k_max']\n",
    "    \n",
    "    print(f\"\\nBest parameters:\")\n",
    "    print(f\"k_max = {best_k_max}\")\n",
    "    print(f\"m = {best_m}\")\n",
    "    print(f\"Best CV R²: {best_result['mean_cv_score']:.4f}\")\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    best_model = FastRandomizedGreedySelection(k_max=best_k_max, m=best_m)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    print(f\"\\nTest set R² with best parameters: {test_score:.4f}\")\n",
    "    \n",
    "    # Selected features\n",
    "    selected_features = np.where(best_model.coef_ != 0)[0]\n",
    "    print(f\"\\nSelected features: {selected_features}\")\n",
    "    print(f\"Number of selected features: {len(selected_features)}\")\n",
    "    \n",
    "    return {\n",
    "        'cv_results': cv_results,\n",
    "        'best_m': best_m,\n",
    "        'best_k_max': best_k_max,\n",
    "        'best_cv_score': best_result['mean_cv_score'],\n",
    "        'test_score': test_score,\n",
    "        'best_model': best_model,\n",
    "        'selected_features': selected_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "def create_comparison_table(regularized_results, rgs_results, splits):\n",
    "    \"\"\"\n",
    "    Create a table comparing test MSE for all methods.\n",
    "    \"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    for dataset_name in splits.keys():\n",
    "        # Get predictions for regularized models\n",
    "        reg_models = regularized_results[dataset_name]\n",
    "        y_test = splits[dataset_name]['y_test']\n",
    "        \n",
    "        # Calculate MSE for each regularized model\n",
    "        for model_name in ['Lasso', 'Ridge', 'ElasticNet']:\n",
    "            y_pred = reg_models[model_name]['predictions']['test']\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Model': model_name,\n",
    "                'Test MSE': mse\n",
    "            })\n",
    "        \n",
    "        # Calculate MSE for RGS\n",
    "        rgs_model = rgs_results[dataset_name]['best_model']\n",
    "        X_test = splits[dataset_name]['X_test']\n",
    "        rgs_pred = rgs_model.predict(X_test)\n",
    "        rgs_mse = mean_squared_error(y_test, rgs_pred)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': 'RGS',\n",
    "            'Test MSE': rgs_mse\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and format\n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    df = df.pivot(index='Dataset', columns='Model', values='Test MSE')\n",
    "    \n",
    "    # Round values for readability\n",
    "    df = df.round(4)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning dataset: Auto Pricing\n",
      "Original shape: (159, 16)\n",
      "Missing values before: 0\n",
      "Duplicate rows before: 0\n",
      "Final shape: (159, 16)\n",
      "Rows removed due to missing values: 0\n",
      "Missing values after: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Cleaning dataset: Satellite Image\n",
      "Original shape: (6435, 37)\n",
      "Missing values before: 0\n",
      "Duplicate rows before: 0\n",
      "Final shape: (6435, 37)\n",
      "Rows removed due to missing values: 0\n",
      "Missing values after: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Cleaning dataset: Bodyfat\n",
      "Original shape: (252, 15)\n",
      "Missing values before: 0\n",
      "Duplicate rows before: 0\n",
      "Final shape: (252, 15)\n",
      "Rows removed due to missing values: 0\n",
      "Missing values after: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Cleaning dataset: Pharynx\n",
      "Original shape: (1000000, 11)\n",
      "Missing values before: 0\n",
      "Duplicate rows before: 0\n",
      "Final shape: (1000000, 11)\n",
      "Rows removed due to missing values: 0\n",
      "Missing values after: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Cleaning dataset: PW\n",
      "Original shape: (200, 11)\n",
      "Missing values before: 0\n",
      "Duplicate rows before: 0\n",
      "Final shape: (200, 11)\n",
      "Rows removed due to missing values: 0\n",
      "Missing values after: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Cleaning dataset: CPU\n",
      "Original shape: (8192, 22)\n",
      "Missing values before: 0\n",
      "Duplicate rows before: 0\n",
      "Final shape: (8192, 22)\n",
      "Rows removed due to missing values: 0\n",
      "Missing values after: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Cleaning dataset: House\n",
      "Original shape: (22784, 17)\n",
      "Missing values before: 0\n",
      "Duplicate rows before: 1\n",
      "Final shape: (22783, 17)\n",
      "Rows removed due to missing values: 1\n",
      "Missing values after: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Cleaning dataset: MeatFat\n",
      "Original shape: (240, 125)\n",
      "Missing values before: 0\n",
      "Duplicate rows before: 20\n",
      "Final shape: (220, 125)\n",
      "Rows removed due to missing values: 20\n",
      "Missing values after: 0\n",
      "Duplicate rows after: 0\n"
     ]
    }
   ],
   "source": [
    "labels = ['Auto Pricing', 'Bodyfat', 'Satellite Image', 'Pharynx', 'PW', 'CPU', 'House', 'MeatFat']\n",
    "data = {}\n",
    "\n",
    "# Load data\n",
    "data['Auto Pricing'] = pd.read_csv('../real_data/207_autoPrice.tsv', sep='\\t')\n",
    "data['Satellite Image'] = pd.read_csv('../real_data/294_satellite_image.tsv', sep='\\t')\n",
    "data['Bodyfat'] = pd.read_csv('../real_data/560_bodyfat.tsv', sep='\\t')\n",
    "data['Pharynx'] = pd.read_csv('../real_data/1196_BNG_pharynx.tsv', sep='\\t')\n",
    "data['PW'] = pd.read_csv('../real_data/229_pwLinear.tsv', sep='\\t')\n",
    "data['CPU'] = pd.read_csv('../real_data/197_cpu_act.tsv', sep='\\t')\n",
    "data['House'] = pd.read_csv('../real_data/574_house_16H.tsv', sep='\\t')\n",
    "data['MeatFat'] = pd.read_csv('../real_data/505_tecator.tsv', sep='\\t')\n",
    "\n",
    "# Clean the datasets\n",
    "cleaned_data = clean_datasets(data)\n",
    "\n",
    "Xs = {label: cleaned_data[label].drop('target', axis=1).values for label in labels}\n",
    "ys = {label: cleaned_data[label]['target'].values for label in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Auto Pricing\n",
      "Training samples: 127\n",
      "Testing samples: 32\n",
      "X_train shape: (127, 15)\n",
      "X_test shape: (32, 15)\n",
      "\n",
      "Dataset: Bodyfat\n",
      "Training samples: 201\n",
      "Testing samples: 51\n",
      "X_train shape: (201, 14)\n",
      "X_test shape: (51, 14)\n",
      "\n",
      "Dataset: Satellite Image\n",
      "Training samples: 5148\n",
      "Testing samples: 1287\n",
      "X_train shape: (5148, 36)\n",
      "X_test shape: (1287, 36)\n",
      "\n",
      "Dataset: Pharynx\n",
      "Training samples: 800000\n",
      "Testing samples: 200000\n",
      "X_train shape: (800000, 10)\n",
      "X_test shape: (200000, 10)\n",
      "\n",
      "Dataset: PW\n",
      "Training samples: 160\n",
      "Testing samples: 40\n",
      "X_train shape: (160, 10)\n",
      "X_test shape: (40, 10)\n",
      "\n",
      "Dataset: CPU\n",
      "Training samples: 6553\n",
      "Testing samples: 1639\n",
      "X_train shape: (6553, 21)\n",
      "X_test shape: (1639, 21)\n",
      "\n",
      "Dataset: House\n",
      "Training samples: 18226\n",
      "Testing samples: 4557\n",
      "X_train shape: (18226, 16)\n",
      "X_test shape: (4557, 16)\n",
      "\n",
      "Dataset: MeatFat\n",
      "Training samples: 176\n",
      "Testing samples: 44\n",
      "X_train shape: (176, 124)\n",
      "X_test shape: (44, 124)\n"
     ]
    }
   ],
   "source": [
    "# Create the splits\n",
    "splits = create_train_test_splits(Xs, ys)\n",
    "\n",
    "# Print split information\n",
    "for label in splits:\n",
    "    print(f\"\\nDataset: {label}\")\n",
    "    print(f\"Training samples: {splits[label]['train_size']}\")\n",
    "    print(f\"Testing samples: {splits[label]['test_size']}\")\n",
    "    print(f\"X_train shape: {splits[label]['X_train'].shape}\")\n",
    "    print(f\"X_test shape: {splits[label]['X_test'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: Auto Pricing\n",
      "Tuning parameters...\n",
      "Testing m values: [1, 2, 4, 5, 7, 8, 10, 11, 13, 15]\n",
      "Testing k_max values: [2, 3, 4, 6, 7, 9, 10, 12, 13, 15]\n",
      "\n",
      "Best parameters:\n",
      "k_max = 4\n",
      "m = 4\n",
      "Best CV R²: 0.8019\n",
      "\n",
      "Test set R² with best parameters: 0.6765\n",
      "\n",
      "Selected features: [0]\n",
      "Number of selected features: 1\n",
      "\n",
      "Processing dataset: Bodyfat\n",
      "Tuning parameters...\n",
      "Testing m values: [1, 2, 3, 5, 6, 8, 9, 11, 12, 14]\n",
      "Testing k_max values: [2, 3, 4, 6, 7, 8, 10, 11, 12, 14]\n",
      "\n",
      "Best parameters:\n",
      "k_max = 6\n",
      "m = 8\n",
      "Best CV R²: 0.9681\n",
      "\n",
      "Test set R² with best parameters: 0.9909\n",
      "\n",
      "Selected features: [0]\n",
      "Number of selected features: 1\n",
      "\n",
      "Processing dataset: Satellite Image\n",
      "Tuning parameters...\n",
      "Testing m values: [1, 4, 8, 12, 16, 20, 24, 28, 32, 36]\n",
      "Testing k_max values: [2, 5, 9, 13, 17, 20, 24, 28, 32, 36]\n",
      "\n",
      "Best parameters:\n",
      "k_max = 13\n",
      "m = 16\n",
      "Best CV R²: 0.7019\n",
      "\n",
      "Test set R² with best parameters: 0.6889\n",
      "\n",
      "Selected features: [0]\n",
      "Number of selected features: 1\n",
      "\n",
      "Processing dataset: Pharynx\n",
      "Tuning parameters...\n",
      "Testing m values: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Testing k_max values: [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "Best parameters:\n",
      "k_max = 9\n",
      "m = 9\n",
      "Best CV R²: 0.4260\n",
      "\n",
      "Test set R² with best parameters: 0.4253\n",
      "\n",
      "Selected features: [0]\n",
      "Number of selected features: 1\n",
      "\n",
      "Processing dataset: PW\n",
      "Tuning parameters...\n",
      "Testing m values: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Testing k_max values: [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "Best parameters:\n",
      "k_max = 7\n",
      "m = 8\n",
      "Best CV R²: 0.7236\n",
      "\n",
      "Test set R² with best parameters: 0.7603\n",
      "\n",
      "Selected features: [0]\n",
      "Number of selected features: 1\n",
      "\n",
      "Processing dataset: CPU\n",
      "Tuning parameters...\n",
      "Testing m values: [1, 3, 5, 7, 9, 12, 14, 16, 18, 21]\n",
      "Testing k_max values: [2, 4, 6, 8, 10, 12, 14, 16, 18, 21]\n",
      "\n",
      "Best parameters:\n",
      "k_max = 21\n",
      "m = 21\n",
      "Best CV R²: 0.7203\n",
      "\n",
      "Test set R² with best parameters: 0.7371\n",
      "\n",
      "Selected features: [0]\n",
      "Number of selected features: 1\n",
      "\n",
      "Processing dataset: House\n",
      "Tuning parameters...\n",
      "Testing m values: [1, 2, 4, 6, 7, 9, 11, 12, 14, 16]\n",
      "Testing k_max values: [2, 3, 5, 6, 8, 9, 11, 12, 14, 16]\n",
      "\n",
      "Best parameters:\n",
      "k_max = 16\n",
      "m = 16\n",
      "Best CV R²: 0.2537\n",
      "\n",
      "Test set R² with best parameters: 0.2587\n",
      "\n",
      "Selected features: [0]\n",
      "Number of selected features: 1\n",
      "\n",
      "Processing dataset: MeatFat\n",
      "Tuning parameters...\n",
      "Testing m values: [1, 14, 28, 42, 55, 69, 83, 96, 110, 124]\n",
      "Testing k_max values: [2, 15, 29, 42, 56, 69, 83, 96, 110, 124]\n",
      "\n",
      "Best parameters:\n",
      "k_max = 42\n",
      "m = 96\n",
      "Best CV R²: 0.9954\n",
      "\n",
      "Test set R² with best parameters: 0.9964\n",
      "\n",
      "Selected features: [0]\n",
      "Number of selected features: 1\n"
     ]
    }
   ],
   "source": [
    "# Run tuning for each dataset\n",
    "tuning_results = {}\n",
    "for dataset_name in splits:\n",
    "    print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "    X_train = splits[dataset_name]['X_train']\n",
    "    X_test = splits[dataset_name]['X_test']\n",
    "    y_train = splits[dataset_name]['y_train']\n",
    "    y_test = splits[dataset_name]['y_test']\n",
    "    n_features = X_train.shape[1]\n",
    "    tuning_results[dataset_name] = tune_rgs_parameters(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: Auto Pricing\n",
      "\n",
      "Training Lasso...\n",
      "Best parameters: {'alpha': 100}\n",
      "Train RMSE: 2318.7822\n",
      "Test RMSE: 2611.5338\n",
      "Train R²: 0.8597\n",
      "Test R²: 0.6167\n",
      "\n",
      "Non-zero coefficients:\n",
      "       Feature  Coefficient\n",
      "6    Feature_6  2054.346455\n",
      "7    Feature_7  1979.916989\n",
      "4    Feature_4  1634.166353\n",
      "1    Feature_1   552.224975\n",
      "2    Feature_2   507.191328\n",
      "3    Feature_3  -369.997229\n",
      "10  Feature_10   235.325631\n",
      "9    Feature_9  -201.703018\n",
      "8    Feature_8   -62.216401\n",
      "14  Feature_14   -56.215267\n",
      "12  Feature_12    21.025979\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters: {'alpha': 10}\n",
      "Train RMSE: 2287.2029\n",
      "Test RMSE: 2533.5819\n",
      "Train R²: 0.8635\n",
      "Test R²: 0.6393\n",
      "\n",
      "Training ElasticNet...\n",
      "Best parameters: {'alpha': 1, 'l1_ratio': 0.9}\n",
      "Train RMSE: 2305.4277\n",
      "Test RMSE: 2502.0830\n",
      "Train R²: 0.8613\n",
      "Test R²: 0.6482\n",
      "\n",
      "Non-zero coefficients:\n",
      "       Feature  Coefficient\n",
      "7    Feature_7  1686.614829\n",
      "6    Feature_6  1506.836812\n",
      "4    Feature_4  1399.350717\n",
      "2    Feature_2   940.708667\n",
      "10  Feature_10   618.752533\n",
      "1    Feature_1   546.245822\n",
      "3    Feature_3  -528.415696\n",
      "11  Feature_11   503.662473\n",
      "14  Feature_14  -405.405922\n",
      "9    Feature_9  -311.288869\n",
      "8    Feature_8  -196.648137\n",
      "13  Feature_13  -123.534236\n",
      "5    Feature_5   -94.052085\n",
      "12  Feature_12    -9.918752\n",
      "0    Feature_0    -3.580981\n",
      "\n",
      "Processing dataset: Bodyfat\n",
      "\n",
      "Training Lasso...\n",
      "Best parameters: {'alpha': 0.1}\n",
      "Train RMSE: 1.3809\n",
      "Test RMSE: 0.5139\n",
      "Train R²: 0.9747\n",
      "Test R²: 0.9943\n",
      "\n",
      "Non-zero coefficients:\n",
      "     Feature  Coefficient\n",
      "0  Feature_0    -7.897724\n",
      "6  Feature_6     0.526593\n",
      "5  Feature_5     0.138641\n",
      "1  Feature_1     0.111054\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters: {'alpha': 1}\n",
      "Train RMSE: 1.3626\n",
      "Test RMSE: 0.6561\n",
      "Train R²: 0.9753\n",
      "Test R²: 0.9907\n",
      "\n",
      "Training ElasticNet...\n",
      "Best parameters: {'alpha': 0.1, 'l1_ratio': 0.9}\n",
      "Train RMSE: 1.3877\n",
      "Test RMSE: 0.6298\n",
      "Train R²: 0.9744\n",
      "Test R²: 0.9915\n",
      "\n",
      "Non-zero coefficients:\n",
      "     Feature  Coefficient\n",
      "0  Feature_0    -7.679033\n",
      "6  Feature_6     0.733007\n",
      "1  Feature_1     0.139148\n",
      "5  Feature_5     0.103801\n",
      "\n",
      "Processing dataset: Satellite Image\n",
      "\n",
      "Training Lasso...\n",
      "Best parameters: {'alpha': 0.001}\n",
      "Train RMSE: 1.1981\n",
      "Test RMSE: 1.2349\n",
      "Train R²: 0.7072\n",
      "Test R²: 0.6887\n",
      "\n",
      "Non-zero coefficients:\n",
      "       Feature  Coefficient\n",
      "8    Feature_8     0.393443\n",
      "25  Feature_25    -0.313252\n",
      "26  Feature_26    -0.277957\n",
      "32  Feature_32     0.264893\n",
      "20  Feature_20     0.257353\n",
      "4    Feature_4     0.221587\n",
      "1    Feature_1    -0.221300\n",
      "9    Feature_9    -0.201564\n",
      "17  Feature_17    -0.194839\n",
      "24  Feature_24     0.185593\n",
      "33  Feature_33    -0.179715\n",
      "10  Feature_10    -0.175487\n",
      "19  Feature_19    -0.169991\n",
      "28  Feature_28     0.168859\n",
      "21  Feature_21    -0.158601\n",
      "5    Feature_5    -0.156466\n",
      "22  Feature_22    -0.150982\n",
      "11  Feature_11    -0.149718\n",
      "2    Feature_2    -0.146223\n",
      "34  Feature_34    -0.142123\n",
      "27  Feature_27    -0.137590\n",
      "15  Feature_15    -0.127412\n",
      "31  Feature_31     0.122258\n",
      "0    Feature_0     0.120509\n",
      "14  Feature_14    -0.116787\n",
      "23  Feature_23    -0.087932\n",
      "7    Feature_7     0.087160\n",
      "29  Feature_29    -0.056215\n",
      "6    Feature_6    -0.047690\n",
      "18  Feature_18    -0.037564\n",
      "3    Feature_3    -0.032216\n",
      "12  Feature_12     0.029876\n",
      "35  Feature_35     0.026145\n",
      "16  Feature_16     0.002606\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters: {'alpha': 100}\n",
      "Train RMSE: 1.1987\n",
      "Test RMSE: 1.2357\n",
      "Train R²: 0.7069\n",
      "Test R²: 0.6883\n",
      "\n",
      "Training ElasticNet...\n",
      "Best parameters: {'alpha': 0.01, 'l1_ratio': 0.1}\n",
      "Train RMSE: 1.1985\n",
      "Test RMSE: 1.2356\n",
      "Train R²: 0.7070\n",
      "Test R²: 0.6884\n",
      "\n",
      "Non-zero coefficients:\n",
      "       Feature  Coefficient\n",
      "8    Feature_8     0.353996\n",
      "25  Feature_25    -0.269589\n",
      "26  Feature_26    -0.260569\n",
      "32  Feature_32     0.254663\n",
      "20  Feature_20     0.242586\n",
      "4    Feature_4     0.219833\n",
      "1    Feature_1    -0.216292\n",
      "17  Feature_17    -0.184949\n",
      "28  Feature_28     0.184123\n",
      "10  Feature_10    -0.171433\n",
      "9    Feature_9    -0.167156\n",
      "21  Feature_21    -0.162553\n",
      "5    Feature_5    -0.162033\n",
      "33  Feature_33    -0.161314\n",
      "24  Feature_24     0.156510\n",
      "22  Feature_22    -0.150267\n",
      "2    Feature_2    -0.134384\n",
      "11  Feature_11    -0.131985\n",
      "14  Feature_14    -0.131571\n",
      "27  Feature_27    -0.126911\n",
      "34  Feature_34    -0.123150\n",
      "19  Feature_19    -0.120658\n",
      "15  Feature_15    -0.119869\n",
      "0    Feature_0     0.118808\n",
      "29  Feature_29    -0.107102\n",
      "23  Feature_23    -0.090427\n",
      "31  Feature_31     0.082951\n",
      "18  Feature_18    -0.066610\n",
      "16  Feature_16     0.052837\n",
      "6    Feature_6    -0.052155\n",
      "12  Feature_12     0.050257\n",
      "7    Feature_7     0.046932\n",
      "13  Feature_13    -0.036853\n",
      "3    Feature_3    -0.026705\n",
      "35  Feature_35     0.023281\n",
      "30  Feature_30    -0.010592\n",
      "\n",
      "Processing dataset: Pharynx\n",
      "\n",
      "Training Lasso...\n",
      "Best parameters: {'alpha': 0.1}\n",
      "Train RMSE: 316.5054\n",
      "Test RMSE: 316.3581\n",
      "Train R²: 0.4261\n",
      "Test R²: 0.4253\n",
      "\n",
      "Non-zero coefficients:\n",
      "     Feature  Coefficient\n",
      "9  Feature_9   233.495107\n",
      "5  Feature_5   -62.855543\n",
      "7  Feature_7   -43.386576\n",
      "0  Feature_0    29.997944\n",
      "8  Feature_8    28.913549\n",
      "2  Feature_2   -22.331382\n",
      "6  Feature_6   -16.611833\n",
      "1  Feature_1   -16.023907\n",
      "3  Feature_3    13.891496\n",
      "4  Feature_4     0.123692\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters: {'alpha': 10}\n",
      "Train RMSE: 316.5052\n",
      "Test RMSE: 316.3593\n",
      "Train R²: 0.4261\n",
      "Test R²: 0.4253\n",
      "\n",
      "Training ElasticNet...\n",
      "Best parameters: {'alpha': 0.001, 'l1_ratio': 0.9}\n",
      "Train RMSE: 316.5052\n",
      "Test RMSE: 316.3592\n",
      "Train R²: 0.4261\n",
      "Test R²: 0.4253\n",
      "\n",
      "Non-zero coefficients:\n",
      "     Feature  Coefficient\n",
      "9  Feature_9   233.520399\n",
      "5  Feature_5   -62.929637\n",
      "7  Feature_7   -43.465323\n",
      "0  Feature_0    30.082197\n",
      "8  Feature_8    28.997516\n",
      "2  Feature_2   -22.420868\n",
      "6  Feature_6   -16.704166\n",
      "1  Feature_1   -16.115130\n",
      "3  Feature_3    13.982643\n",
      "4  Feature_4     0.223385\n",
      "\n",
      "Processing dataset: PW\n",
      "\n",
      "Training Lasso...\n",
      "Best parameters: {'alpha': 0.0001}\n",
      "Train RMSE: 2.1463\n",
      "Test RMSE: 1.8363\n",
      "Train R²: 0.7843\n",
      "Test R²: 0.7568\n",
      "\n",
      "Non-zero coefficients:\n",
      "     Feature  Coefficient\n",
      "0  Feature_0    -2.736625\n",
      "4  Feature_4     1.601720\n",
      "5  Feature_5     1.134893\n",
      "1  Feature_1     1.103869\n",
      "6  Feature_6     0.916063\n",
      "2  Feature_2     0.687540\n",
      "9  Feature_9     0.332092\n",
      "8  Feature_8     0.302253\n",
      "3  Feature_3     0.284705\n",
      "7  Feature_7     0.122363\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters: {'alpha': 0.0001}\n",
      "Train RMSE: 2.1463\n",
      "Test RMSE: 1.8364\n",
      "Train R²: 0.7843\n",
      "Test R²: 0.7568\n",
      "\n",
      "Training ElasticNet...\n",
      "Best parameters: {'alpha': 0.0001, 'l1_ratio': 0.9}\n",
      "Train RMSE: 2.1463\n",
      "Test RMSE: 1.8363\n",
      "Train R²: 0.7843\n",
      "Test R²: 0.7568\n",
      "\n",
      "Non-zero coefficients:\n",
      "     Feature  Coefficient\n",
      "0  Feature_0    -2.736609\n",
      "4  Feature_4     1.601716\n",
      "5  Feature_5     1.134897\n",
      "1  Feature_1     1.103869\n",
      "6  Feature_6     0.916061\n",
      "2  Feature_2     0.687542\n",
      "9  Feature_9     0.332098\n",
      "8  Feature_8     0.302258\n",
      "3  Feature_3     0.284715\n",
      "7  Feature_7     0.122373\n",
      "\n",
      "Processing dataset: CPU\n",
      "\n",
      "Training Lasso...\n",
      "Best parameters: {'alpha': 0.01}\n",
      "Train RMSE: 9.7616\n",
      "Test RMSE: 8.8784\n",
      "Train R²: 0.7263\n",
      "Test R²: 0.7369\n",
      "\n",
      "Non-zero coefficients:\n",
      "       Feature  Coefficient\n",
      "20  Feature_20     9.385856\n",
      "18  Feature_18    -7.726295\n",
      "5    Feature_5    -4.164255\n",
      "16  Feature_16    -3.105899\n",
      "11  Feature_11    -2.739759\n",
      "10  Feature_10     2.536414\n",
      "19  Feature_19    -2.391574\n",
      "17  Feature_17     2.321162\n",
      "9    Feature_9    -2.008215\n",
      "7    Feature_7    -1.076917\n",
      "0    Feature_0    -1.031307\n",
      "8    Feature_8    -0.963748\n",
      "4    Feature_4    -0.540829\n",
      "13  Feature_13     0.536152\n",
      "1    Feature_1     0.323178\n",
      "12  Feature_12     0.322989\n",
      "14  Feature_14     0.304571\n",
      "3    Feature_3     0.277574\n",
      "6    Feature_6    -0.245630\n",
      "2    Feature_2    -0.208590\n",
      "15  Feature_15    -0.089648\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters: {'alpha': 10}\n",
      "Train RMSE: 9.7607\n",
      "Test RMSE: 8.8760\n",
      "Train R²: 0.7264\n",
      "Test R²: 0.7371\n",
      "\n",
      "Training ElasticNet...\n",
      "Best parameters: {'alpha': 0.01, 'l1_ratio': 0.9}\n",
      "Train RMSE: 9.7619\n",
      "Test RMSE: 8.8781\n",
      "Train R²: 0.7263\n",
      "Test R²: 0.7370\n",
      "\n",
      "Non-zero coefficients:\n",
      "       Feature  Coefficient\n",
      "20  Feature_20     9.367115\n",
      "18  Feature_18    -7.724548\n",
      "5    Feature_5    -4.091069\n",
      "16  Feature_16    -3.085705\n",
      "11  Feature_11    -2.694820\n",
      "10  Feature_10     2.496404\n",
      "19  Feature_19    -2.383531\n",
      "17  Feature_17     2.232936\n",
      "9    Feature_9    -1.995735\n",
      "7    Feature_7    -1.077392\n",
      "0    Feature_0    -1.032104\n",
      "8    Feature_8    -0.965723\n",
      "4    Feature_4    -0.554128\n",
      "13  Feature_13     0.537906\n",
      "1    Feature_1     0.325368\n",
      "14  Feature_14     0.323805\n",
      "12  Feature_12     0.314339\n",
      "3    Feature_3     0.290269\n",
      "6    Feature_6    -0.259052\n",
      "2    Feature_2    -0.207100\n",
      "15  Feature_15    -0.105124\n",
      "\n",
      "Processing dataset: House\n",
      "\n",
      "Training Lasso...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 10}\n",
      "Train RMSE: 45539.6317\n",
      "Test RMSE: 44974.0903\n",
      "Train R²: 0.2615\n",
      "Test R²: 0.2588\n",
      "\n",
      "Non-zero coefficients:\n",
      "       Feature   Coefficient\n",
      "5    Feature_5 -40554.427371\n",
      "7    Feature_7  34374.956484\n",
      "6    Feature_6 -25401.302666\n",
      "9    Feature_9  15494.137719\n",
      "4    Feature_4 -10124.229677\n",
      "13  Feature_13  -9436.530945\n",
      "2    Feature_2   9315.902786\n",
      "11  Feature_11  -9063.021253\n",
      "8    Feature_8  -7001.988187\n",
      "14  Feature_14  -5758.068640\n",
      "3    Feature_3   5081.523706\n",
      "12  Feature_12  -4889.923386\n",
      "1    Feature_1  -3474.208783\n",
      "15  Feature_15  -2633.593492\n",
      "0    Feature_0   2546.083625\n",
      "10  Feature_10    -49.115521\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters: {'alpha': 10}\n",
      "Train RMSE: 45539.9237\n",
      "Test RMSE: 44969.8905\n",
      "Train R²: 0.2615\n",
      "Test R²: 0.2589\n",
      "\n",
      "Training ElasticNet...\n",
      "Best parameters: {'alpha': 0.001, 'l1_ratio': 0.1}\n",
      "Train RMSE: 45541.2733\n",
      "Test RMSE: 44966.3930\n",
      "Train R²: 0.2615\n",
      "Test R²: 0.2590\n",
      "\n",
      "Non-zero coefficients:\n",
      "       Feature   Coefficient\n",
      "5    Feature_5 -38633.042333\n",
      "7    Feature_7  33235.570600\n",
      "6    Feature_6 -24191.517117\n",
      "9    Feature_9  15774.657180\n",
      "4    Feature_4 -10249.875886\n",
      "2    Feature_2   9509.925658\n",
      "13  Feature_13  -9460.768829\n",
      "11  Feature_11  -9281.476398\n",
      "8    Feature_8  -6975.301959\n",
      "14  Feature_14  -5795.287235\n",
      "3    Feature_3   5278.452868\n",
      "12  Feature_12  -4900.454288\n",
      "1    Feature_1  -3452.925165\n",
      "15  Feature_15  -2664.673019\n",
      "0    Feature_0   2548.142561\n",
      "10  Feature_10    -29.781162\n",
      "\n",
      "Processing dataset: MeatFat\n",
      "\n",
      "Training Lasso...\n",
      "Best parameters: {'alpha': 0.01}\n",
      "Train RMSE: 0.6231\n",
      "Test RMSE: 0.7535\n",
      "Train R²: 0.9982\n",
      "Test R²: 0.9965\n",
      "\n",
      "Non-zero coefficients:\n",
      "         Feature  Coefficient\n",
      "122  Feature_122   -11.397717\n",
      "123  Feature_123    -2.406783\n",
      "103  Feature_103    -1.053161\n",
      "115  Feature_115    -0.824821\n",
      "113  Feature_113     0.760876\n",
      "108  Feature_108    -0.753672\n",
      "102  Feature_102    -0.663818\n",
      "119  Feature_119     0.354672\n",
      "101  Feature_101     0.351916\n",
      "109  Feature_109     0.334379\n",
      "111  Feature_111     0.279179\n",
      "106  Feature_106     0.220613\n",
      "112  Feature_112    -0.212205\n",
      "114  Feature_114     0.183467\n",
      "104  Feature_104     0.160441\n",
      "105  Feature_105     0.108552\n",
      "117  Feature_117     0.098419\n",
      "118  Feature_118     0.073084\n",
      "116  Feature_116     0.069611\n",
      "107  Feature_107     0.058180\n",
      "110  Feature_110    -0.057298\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters: {'alpha': 1}\n",
      "Train RMSE: 0.6703\n",
      "Test RMSE: 0.9226\n",
      "Train R²: 0.9979\n",
      "Test R²: 0.9948\n",
      "\n",
      "Training ElasticNet...\n",
      "Best parameters: {'alpha': 0.01, 'l1_ratio': 0.9}\n",
      "Train RMSE: 0.6205\n",
      "Test RMSE: 0.7734\n",
      "Train R²: 0.9982\n",
      "Test R²: 0.9963\n",
      "\n",
      "Non-zero coefficients:\n",
      "         Feature  Coefficient\n",
      "122  Feature_122   -11.103966\n",
      "123  Feature_123    -2.417991\n",
      "103  Feature_103    -1.176178\n",
      "115  Feature_115    -0.871444\n",
      "102  Feature_102    -0.840655\n",
      "113  Feature_113     0.769173\n",
      "108  Feature_108    -0.759935\n",
      "119  Feature_119     0.504382\n",
      "109  Feature_109     0.329399\n",
      "101  Feature_101     0.322656\n",
      "111  Feature_111     0.254954\n",
      "114  Feature_114     0.235918\n",
      "112  Feature_112    -0.212916\n",
      "106  Feature_106     0.205516\n",
      "104  Feature_104     0.197733\n",
      "105  Feature_105     0.134627\n",
      "117  Feature_117     0.108826\n",
      "116  Feature_116     0.087714\n",
      "110  Feature_110    -0.082262\n",
      "118  Feature_118     0.063007\n",
      "107  Feature_107     0.050180\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "results = train_regularized_models(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test MSE Comparison:\n",
      "Model              ElasticNet         Lasso           RGS         Ridge\n",
      "Dataset                                                                \n",
      "Auto Pricing     6.260419e+06  6.820109e+06  5.756188e+06  6.419037e+06\n",
      "Bodyfat          3.966000e-01  2.641000e-01  4.246000e-01  4.305000e-01\n",
      "CPU              7.882120e+01  7.882630e+01  7.879250e+01  7.878400e+01\n",
      "House            2.021976e+09  2.022669e+09  2.022925e+09  2.022291e+09\n",
      "MeatFat          5.982000e-01  5.678000e-01  5.843000e-01  8.511000e-01\n",
      "PW               3.372000e+00  3.372000e+00  3.323100e+00  3.372500e+00\n",
      "Pharynx          1.000831e+05  1.000825e+05  1.000835e+05  1.000832e+05\n",
      "Satellite Image  1.526600e+00  1.525100e+00  1.524000e+00  1.526800e+00\n",
      "\n",
      "Best performing model for each dataset:\n",
      "Dataset\n",
      "Auto Pricing              RGS\n",
      "Bodyfat                 Lasso\n",
      "CPU                     Ridge\n",
      "House              ElasticNet\n",
      "MeatFat                 Lasso\n",
      "PW                        RGS\n",
      "Pharynx                 Lasso\n",
      "Satellite Image           RGS\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "comparison_table = create_comparison_table(results, tuning_results, splits)\n",
    "\n",
    "# Display table\n",
    "print(\"\\nTest MSE Comparison:\")\n",
    "print(comparison_table)\n",
    "\n",
    "# Find best model for each dataset\n",
    "best_models = comparison_table.idxmin(axis=1)\n",
    "print(\"\\nBest performing model for each dataset:\")\n",
    "print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
