{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Import RGS components\n",
    "from rgs.src.rgs.core.rgs import RGSCV\n",
    "from rgs.src.rgs.mse import create_mse_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_datasets(data):\n",
    "    \"\"\"Clean datasets by removing missing values and duplicate rows.\"\"\"\n",
    "    cleaned_data = {}\n",
    "    \n",
    "    for label, df in data.items():\n",
    "        print(f\"Cleaning {label}: {df.shape} -> \", end=\"\")\n",
    "        df_cleaned = df.dropna().drop_duplicates()\n",
    "        print(f\"{df_cleaned.shape}\")\n",
    "        cleaned_data[label] = df_cleaned\n",
    "    \n",
    "    return cleaned_data\n",
    "\n",
    "def evaluate_methods_cv_only(Xs, ys, cv=10):\n",
    "    \"\"\"Evaluate baseline methods using only their internal CV.\"\"\"\n",
    "    \n",
    "    baseline_models = {\n",
    "        'LassoCV': LassoCV(cv=cv, random_state=42, max_iter=10000),\n",
    "        'RidgeCV': RidgeCV(cv=cv), \n",
    "        'ElasticNetCV': ElasticNetCV(cv=cv, random_state=42, max_iter=10000,\n",
    "                                   l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    for dataset_name in Xs.keys():\n",
    "        print(f\"Evaluating baselines on {dataset_name}...\")\n",
    "        X, y = Xs[dataset_name], ys[dataset_name]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        for method_name, model in baseline_models.items():\n",
    "            model.fit(X_scaled, y)\n",
    "            cv_score = model.score(X_scaled, y)\n",
    "            \n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Method': method_name, \n",
    "                'CV_R2': cv_score\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results).pivot(index='Dataset', columns='Method', values='CV_R2')\n",
    "\n",
    "def evaluate_rgs_cv(Xs, ys, cv=10):\n",
    "    \"\"\"Evaluate RGS using cross-validation with the same setup as simulation.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    for dataset_name in Xs.keys():\n",
    "        print(f\"Evaluating RGS on {dataset_name}...\")\n",
    "        X, y = Xs[dataset_name], ys[dataset_name]\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Setup RGS parameters\n",
    "        max_k = min(n_features, 25)\n",
    "        m_grid = [round(1 + i * (n_features-1) / 9) for i in range(10)]\n",
    "        \n",
    "        # Estimate sigma from data\n",
    "        temp_model = LinearRegression().fit(X_scaled, y)\n",
    "        residuals = y - temp_model.predict(X_scaled)\n",
    "        estimated_sigma = np.std(residuals)\n",
    "        \n",
    "        # Use the same scorer as simulation\n",
    "        make_k_scorer = create_mse_scorer(\n",
    "            sigma=estimated_sigma,\n",
    "            n=n_samples,\n",
    "            p=n_features\n",
    "        )\n",
    "        \n",
    "        rgscv = RGSCV(\n",
    "            k_max=max_k,\n",
    "            m_grid=m_grid,\n",
    "            n_estimators=500,\n",
    "            n_resample_iter=7,\n",
    "            method='fs',\n",
    "            cv=cv,\n",
    "            scoring=make_k_scorer,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        rgscv.fit(X_scaled, y)\n",
    "        \n",
    "        results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Method': 'RGS',\n",
    "            'CV_R2': rgscv.score(X_scaled, y),\n",
    "            'Best_k': rgscv.k_,\n",
    "            'Best_m': rgscv.m_\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_cv_comparison_table(baseline_results, rgs_results):\n",
    "    \"\"\"Create comparison table for CV R² scores.\"\"\"\n",
    "    combined_results = baseline_results.copy()\n",
    "    rgs_df = pd.DataFrame(rgs_results)\n",
    "    combined_results['RGS'] = rgs_df.set_index('Dataset')['CV_R2']\n",
    "    return combined_results.round(3)\n",
    "\n",
    "def create_parameter_table(rgs_results):\n",
    "    \"\"\"Create table showing RGS parameter selections.\"\"\"\n",
    "    rgs_df = pd.DataFrame(rgs_results)\n",
    "    return rgs_df[['Dataset', 'Best_k', 'Best_m']].set_index('Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "Cleaning datasets...\n",
      "Cleaning Auto Pricing: (159, 16) -> (159, 16)\n",
      "Cleaning Sunspots: (235, 13) -> (235, 13)\n",
      "Cleaning Bodyfat: (252, 15) -> (252, 15)\n",
      "Cleaning PW: (200, 11) -> (200, 11)\n",
      "Cleaning CPU: (8192, 22) -> (8192, 22)\n",
      "Cleaning House: (22784, 17) -> (22783, 17)\n",
      "Cleaning MeatFat: (240, 125) -> (220, 125)\n",
      "\n",
      "============================================================\n",
      "EVALUATING BASELINE METHODS\n",
      "============================================================\n",
      "Evaluating baselines on Auto Pricing...\n",
      "Evaluating baselines on Bodyfat...\n",
      "Evaluating baselines on Sunspots...\n",
      "Evaluating baselines on PW...\n",
      "Evaluating baselines on CPU...\n",
      "Evaluating baselines on House...\n",
      "Evaluating baselines on MeatFat...\n",
      "\n",
      "============================================================\n",
      "EVALUATING RGS\n",
      "============================================================\n",
      "Evaluating RGS on Auto Pricing...\n",
      "Evaluating RGS on Bodyfat...\n",
      "Evaluating RGS on Sunspots...\n",
      "Evaluating RGS on PW...\n",
      "Evaluating RGS on CPU...\n",
      "Evaluating RGS on House...\n",
      "Evaluating RGS on MeatFat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lg_fridge/Documents/Princeton/Research/RFS/notebooks/../rgs/src/rgs/core/rgs.py:145: UserWarning: Large feature count (>100) detected. Performance may be impacted.\n",
      "  warnings.warn(\"Large feature count (>100) detected. Performance may be impacted.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "CV R² Comparison Table:\n",
      "Method        ElasticNetCV  LassoCV  RidgeCV    RGS\n",
      "Dataset                                            \n",
      "Auto Pricing         0.816    0.826    0.847  0.826\n",
      "Bodyfat              0.978    0.978    0.978  0.977\n",
      "CPU                  0.729    0.729    0.729  0.729\n",
      "House                0.142    0.261    0.261  0.261\n",
      "MeatFat              0.998    0.998    0.998  0.998\n",
      "PW                   0.784    0.785    0.783  0.784\n",
      "Sunspots             0.887    0.888    0.885  0.880\n",
      "\n",
      "Best Method per Dataset:\n",
      "Auto Pricing: RidgeCV (0.847)\n",
      "Bodyfat: ElasticNetCV (0.978)\n",
      "CPU: ElasticNetCV (0.729)\n",
      "House: LassoCV (0.261)\n",
      "MeatFat: ElasticNetCV (0.998)\n",
      "PW: LassoCV (0.785)\n",
      "Sunspots: LassoCV (0.888)\n",
      "\n",
      "RGS Parameter Selection Table:\n",
      "              Best_k  Best_m\n",
      "Dataset                     \n",
      "Auto Pricing       2       7\n",
      "Bodyfat            1      13\n",
      "Sunspots           2       6\n",
      "PW                 9       2\n",
      "CPU               20      10\n",
      "House             15       6\n",
      "MeatFat           10     110\n",
      "\n",
      "Summary Statistics:\n",
      "              Mean_R2  Std_R2  Min_R2  Max_R2  Wins\n",
      "Method                                             \n",
      "ElasticNetCV    0.762   0.291   0.142   0.998     3\n",
      "LassoCV         0.781   0.249   0.261   0.998     3\n",
      "RidgeCV         0.783   0.250   0.261   0.998     1\n",
      "RGS             0.779   0.248   0.261   0.998     0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "labels = ['Auto Pricing', 'Bodyfat', 'Sunspots', 'PW', 'CPU', 'House', 'MeatFat']\n",
    "data = {}\n",
    "\n",
    "data['Auto Pricing'] = pd.read_csv('../real_data/207_autoPrice.tsv', sep='\\t')\n",
    "data['Sunspots'] = pd.read_csv('../real_data/695_chatfield_4.tsv', sep='\\t')\n",
    "data['Bodyfat'] = pd.read_csv('../real_data/560_bodyfat.tsv', sep='\\t')\n",
    "# data['Pharynx'] = pd.read_csv('../real_data/1196_BNG_pharynx.tsv', sep='\\t')\n",
    "data['PW'] = pd.read_csv('../real_data/229_pwLinear.tsv', sep='\\t')\n",
    "data['CPU'] = pd.read_csv('../real_data/197_cpu_act.tsv', sep='\\t')\n",
    "data['House'] = pd.read_csv('../real_data/574_house_16H.tsv', sep='\\t')\n",
    "data['MeatFat'] = pd.read_csv('../real_data/505_tecator.tsv', sep='\\t')\n",
    "\n",
    "# Clean datasets\n",
    "print(\"\\nCleaning datasets...\")\n",
    "cleaned_data = clean_datasets(data)\n",
    "\n",
    "# Prepare X and y\n",
    "Xs = {label: cleaned_data[label].drop('target', axis=1).values for label in labels}\n",
    "ys = {label: cleaned_data[label]['target'].values for label in labels}\n",
    "\n",
    "# Evaluate baseline methods\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING BASELINE METHODS\")\n",
    "print(\"=\"*60)\n",
    "baseline_results = evaluate_methods_cv_only(Xs, ys)\n",
    "\n",
    "# Evaluate RGS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING RGS\")\n",
    "print(\"=\"*60)\n",
    "rgs_results = evaluate_rgs_cv(Xs, ys)\n",
    "\n",
    "# Create and display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comparison tables\n",
    "cv_comparison_table = create_cv_comparison_table(baseline_results, rgs_results)\n",
    "parameter_table = create_parameter_table(rgs_results)\n",
    "\n",
    "print(\"\\nCV R² Comparison Table:\")\n",
    "print(cv_comparison_table)\n",
    "\n",
    "# Find best method per dataset\n",
    "best_methods = cv_comparison_table.idxmax(axis=1)\n",
    "print(\"\\nBest Method per Dataset:\")\n",
    "for dataset, method in best_methods.items():\n",
    "    score = cv_comparison_table.loc[dataset, method]\n",
    "    print(f\"{dataset}: {method} ({score:.3f})\")\n",
    "\n",
    "print(\"\\nRGS Parameter Selection Table:\")\n",
    "print(parameter_table)\n",
    "\n",
    "# Summary statistics table\n",
    "print(\"\\nSummary Statistics:\")\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Mean_R2': cv_comparison_table.mean(),\n",
    "    'Std_R2': cv_comparison_table.std(),\n",
    "    'Min_R2': cv_comparison_table.min(),\n",
    "    'Max_R2': cv_comparison_table.max(),\n",
    "    'Wins': [sum(best_methods == method) for method in cv_comparison_table.columns]\n",
    "}).round(3)\n",
    "print(summary_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
