{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from RGS import FastRandomizedGreedySelection, RandomizedGreedySelection\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n, p = 5000, 500  # 100 samples, 50 features\n",
    "\n",
    "# Create base features\n",
    "X = np.random.randn(n, p)\n",
    "\n",
    "# Introduce correlations\n",
    "X[:, 1] = 0 * X[:, 0] + 0.3 * np.random.randn(n)  # Correlated with feature 0\n",
    "X[:, 3] = 0 * X[:, 2] + 0.4 * np.random.randn(n)  # Correlated with feature 2\n",
    "X[:, 5] = 0 * X[:, 0] + 0 * X[:, 4] + 0.1 * np.random.randn(n)  # Correlated with features 0 and 4\n",
    "\n",
    "# Create true coefficients (some zero, some non-zero)\n",
    "true_coef = np.zeros(p)\n",
    "true_coef[:6] = [1.5, -0.8, 1.2, -0.5, 0.7, -0.3]  # Only first 6 features are relevant\n",
    "\n",
    "# Create the target variable (linear model)\n",
    "y = X @ true_coef + np.random.normal(0, 1, n)  # Add some noise\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs = RandomizedGreedySelection(k=10, m=200) # Original implementation\n",
    "rfs.fit(X, y) # 30.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs2 = FastRandomizedGreedySelection(k=10, m=200, tol=1) # Keep only feature sets appearing more than 1 time\n",
    "rfs2.fit(X, y) # 2.2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the above approach is that at each step, the total number of feature sets goes down. We also introduce a small amount of bias. We can overcome this using resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs3 = FastRandomizedGreedySelection(k=10, m=200, tol=0, resample=True)\n",
    "rfs3.fit(X, y) # 6.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs4 = FastRandomizedGreedySelection(k=10, m=200, tol=1, resample=True) # Both resample and filter\n",
    "rfs4.fit(X, y) # 3.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV()\n",
    "lasso.fit(X, y) # 0.5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfs': 1.02050835495605,\n",
       " 'rfs2': 1.0196394200227814,\n",
       " 'rfs3': 1.0200621735543476,\n",
       " 'rfs4': 1.020219437471009,\n",
       " 'lasso': 1.0409735104433}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = {\"rfs\" : rfs, \n",
    "              \"rfs2\" : rfs2,\n",
    "              \"rfs3\" : rfs3,\n",
    "              \"rfs4\" : rfs4,\n",
    "              \"lasso\" : lasso\n",
    "              }\n",
    "results = {}\n",
    "for name, estimator in estimators.items():\n",
    "    results[name] = mean_squared_error(estimator.predict(X_test), y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare feature ranking\n",
    "\n",
    "Note that in our generative model, the relevant features are [0, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   4,   1,   3, 321, 439,   9, 230, 493, 176, 339, 385,\n",
       "       224,  57, 143, 147, 494, 234, 434, 303, 248, 343, 204, 259, 462,\n",
       "       177, 170, 179, 160, 161, 162, 163, 178, 164, 165, 166, 169, 167,\n",
       "       175, 174, 168, 173, 172, 171, 158, 159, 150, 157, 156, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144,\n",
       "       145, 146, 148, 149, 181, 151, 152, 153, 154, 155, 180, 189, 182,\n",
       "       212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226,\n",
       "       227, 228, 229, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241,\n",
       "       213, 211, 183, 210, 184, 185, 186, 187, 188, 127, 190, 191, 192,\n",
       "       193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206,\n",
       "       207, 208, 209, 128, 121, 126,  65,  36,  37,  38,  39,  40,  41,\n",
       "        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "        55,  56,  58,  59,  60,  61,  62,  63,  35,  34,  33,  18,   5,\n",
       "         6,   7,   8,  10,  11,  12,  13,  14,  15,  16,  17,  19,  32,\n",
       "        20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  64,\n",
       "        66, 125,  67,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "       243, 122, 123, 124,  97,  96,  95,  80,  68,  69,  70,  71,  72,\n",
       "        73,  74,  75,  76,  77,  78,  79,  81,  94,  82,  83,  84,  85,\n",
       "        86,  87,  88,  89,  90,  91,  92,  93, 242, 499, 244, 433, 405,\n",
       "       406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
       "       419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
       "       404, 403, 402, 387, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
       "       383, 384, 386, 388, 401, 389, 390, 391, 392, 393, 394, 395, 396,\n",
       "       397, 398, 399, 400, 432, 435, 372, 436, 469, 470, 471, 472, 473,\n",
       "       474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
       "       487, 488, 489, 490, 491, 492, 495, 496, 497, 468, 467, 466, 450,\n",
       "       437, 438, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 451,\n",
       "       465, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463, 464,\n",
       "       373, 371, 245, 307, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 304, 305, 277, 276, 275, 260, 246, 247, 498, 250,\n",
       "       251, 252, 253, 254, 255, 256, 257, 258, 261, 274, 262, 263, 264,\n",
       "       265, 266, 267, 268, 269, 270, 271, 272, 273, 306, 308, 370, 309,\n",
       "       342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "       356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "       369, 341, 340, 338, 323, 310, 311, 312, 313, 314, 315, 316, 317,\n",
       "       318, 319, 320, 322, 324, 337, 325, 326, 327, 328, 329, 330, 331,\n",
       "       332, 333, 334, 335, 336, 249])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(lasso.coef_).argsort()[::-1] # Feature 5 only shows up in ~170th place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   1,   4,   3,   5, 439, 321,   9, 493, 385, 230, 176,\n",
       "       339, 143, 209, 147, 105, 480, 224, 449, 248,  60,  57, 346, 153,\n",
       "       204, 343, 472, 164, 159, 160, 178, 161, 162, 163, 177, 169, 165,\n",
       "       166, 170, 175, 174, 167, 173, 172, 171, 168, 150, 158, 141, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 157, 144,\n",
       "       145, 146, 148, 149, 180, 151, 152, 154, 155, 156, 179, 190, 181,\n",
       "       227, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226,\n",
       "       228, 182, 229, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
       "       241, 213, 212, 211, 210, 183, 184, 185, 186, 187, 188, 189, 128,\n",
       "       191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,\n",
       "       205, 206, 207, 208, 129, 120, 127,  49,  37,  38,  39,  40,  41,\n",
       "        42,  43,  44,  45,  46,  47,  48,  50,  35,  51,  52,  53,  54,\n",
       "        55,  56,  58,  59,  61,  62,  63,  64,  36,  34,  66,  19,   6,\n",
       "         7,   8,  10,  11,  12,  13,  14,  15,  16,  17,  18,  20,  33,\n",
       "        21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  65,\n",
       "        67, 126, 112,  99, 100, 101, 102, 103, 104, 106, 107, 108, 109,\n",
       "       110, 111, 113,  97, 114, 115, 116, 117, 118, 119, 243, 121, 122,\n",
       "       123, 124, 125,  98,  96,  68,  81,  69,  70,  71,  72,  73,  74,\n",
       "        75,  76,  77,  78,  79,  80,  82,  95,  83,  84,  85,  86,  87,\n",
       "        88,  89,  90,  91,  92,  93,  94, 242, 499, 244, 403, 405, 406,\n",
       "       407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
       "       420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 404,\n",
       "       402, 245, 401, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
       "       383, 384, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396,\n",
       "       397, 398, 399, 400, 432, 433, 434, 435, 468, 469, 470, 471, 473,\n",
       "       474, 475, 476, 477, 478, 479, 481, 482, 483, 484, 485, 486, 487,\n",
       "       488, 489, 490, 491, 492, 494, 495, 496, 497, 467, 466, 465, 450,\n",
       "       436, 437, 438, 440, 441, 442, 443, 444, 445, 446, 447, 448, 451,\n",
       "       464, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
       "       372, 371, 370, 305, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 276, 275, 274, 259, 246, 247, 498, 250,\n",
       "       251, 252, 253, 254, 255, 256, 257, 258, 260, 273, 261, 262, 263,\n",
       "       264, 265, 266, 267, 268, 269, 270, 271, 272, 304, 306, 369, 307,\n",
       "       340, 341, 342, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354,\n",
       "       355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
       "       368, 338, 337, 336, 320, 308, 309, 310, 311, 312, 313, 314, 315,\n",
       "       316, 317, 318, 319, 322, 335, 323, 324, 325, 326, 327, 328, 329,\n",
       "       330, 331, 332, 333, 334, 249])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(rfs2.coef_).argsort()[::-1] # Feature 5 shows up in 6th place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare total number of feature subsets at step k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rfs2</th>\n",
       "      <th>rfs3</th>\n",
       "      <th>rfs4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>998</td>\n",
       "      <td>1000</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>986</td>\n",
       "      <td>1000</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>949</td>\n",
       "      <td>1000</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>883</td>\n",
       "      <td>1000</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>785</td>\n",
       "      <td>1000</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>671</td>\n",
       "      <td>1000</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>568</td>\n",
       "      <td>1000</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>466</td>\n",
       "      <td>1000</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rfs2  rfs3  rfs4\n",
       "0  1000  1000  1000\n",
       "1  1000  1000  1000\n",
       "2   998  1000   998\n",
       "3   986  1000   988\n",
       "4   949  1000   983\n",
       "5   883  1000   960\n",
       "6   785  1000   956\n",
       "7   671  1000   927\n",
       "8   568  1000   914\n",
       "9   466  1000   913"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_subsets = {}\n",
    "for name, estimator in estimators.items():\n",
    "    if name not in [\"lasso\", \"rfs\"]:\n",
    "        n_subsets[name] = [sum(estimator.trajectory[j].values()) for j in range(10)]\n",
    "pd.DataFrame(n_subsets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
