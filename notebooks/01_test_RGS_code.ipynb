{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from old_code.RGS import FastRandomizedGreedySelection, RandomizedGreedySelection\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n, p = 5000, 500  # 5000 samples, 500 features\n",
    "\n",
    "# Create base features\n",
    "X = np.random.randn(n, p)\n",
    "\n",
    "X[:, 1] = 0 * X[:, 0] + 0.3 * np.random.randn(n)  # Correlated with feature 0\n",
    "X[:, 3] = 0 * X[:, 2] + 0.4 * np.random.randn(n)  # Correlated with feature 2\n",
    "X[:, 5] = 0 * X[:, 0] + 0 * X[:, 4] + 0.1 * np.random.randn(n)  # Correlated with features 0 and 4\n",
    "true_coef = np.zeros(p)\n",
    "true_coef[:6] = [1.5, -0.8, 1.2, -0.5, 0.7, -0.3]  # Only first 6 features are relevant\n",
    "y = X @ true_coef + np.random.normal(0, 1, n)  # Add some noise\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgs = RandomizedGreedySelection(k=10, m=200) # Original implementation\n",
    "rgs.fit(X_train, y_train) # 27.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgs1 = FastRandomizedGreedySelection(k=10, m=200)\n",
    "rgs1.fit(X_train, y_train) # 7.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only feature sets appearing more than 1 time, we increase the number of estimators to 5000\n",
    "rgs2 = FastRandomizedGreedySelection(k=10, m=200, tol=1, n_estimators=5000) \n",
    "rgs2.fit(X_train, y_train) # 7.7s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the above approach is that at each step, the total number of feature sets goes down. We also introduce a small amount of bias. We can overcome this using resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgs3 = FastRandomizedGreedySelection(k=10, m=200, tol=0, resample=True)\n",
    "rgs3.fit(X_train, y_train) # 5.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both resample and filter. No. of estimators increased to 2500\n",
    "rgs4 = FastRandomizedGreedySelection(k=10, m=200, tol=1, n_estimators=2500, resample=True)\n",
    "rgs4.fit(X_train, y_train) # 6.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV()\n",
    "lasso.fit(X_train, y_train) # 0.4s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rgs': 0.00605774981588647,\n",
       " 'rgs1': 0.006397642366785582,\n",
       " 'rgs2': 0.007304560456249431,\n",
       " 'rgs3': 0.005993455427545296,\n",
       " 'rgs4': 0.006570436937307765,\n",
       " 'lasso': 0.0148757421939166}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = {\"rgs\" : rgs,\n",
    "              \"rgs1\" : rgs1,\n",
    "              \"rgs2\" : rgs2,\n",
    "              \"rgs3\" : rgs3,\n",
    "              \"rgs4\" : rgs4,\n",
    "              \"lasso\" : lasso\n",
    "              }\n",
    "results = {}\n",
    "for name, estimator in estimators.items():\n",
    "    results[name] = mean_squared_error(estimator.predict(X_test), X_test @ true_coef)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the resampling trick seems to reduce running time by a bit but without sacrificing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare feature ranking\n",
    "\n",
    "Note that in our generative model, the relevant features are [0, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   4,   1,   3, 439, 321, 224, 230, 494, 428, 129, 434,\n",
       "       303,  57, 339,  90, 206, 176, 471, 343, 462, 123, 480, 263, 147,\n",
       "       112, 484,  25, 311, 292,  49, 497, 223,   9, 460, 402, 183, 131,\n",
       "       209, 418, 394,  80, 210, 499, 180, 141, 195, 143, 493, 461, 477,\n",
       "       163, 152, 166, 144, 145, 146, 479, 148, 149, 150, 151, 153, 162,\n",
       "       154, 165, 156, 164, 157, 158, 159, 160, 161, 155, 454, 142, 140,\n",
       "       115, 116, 117, 118, 119, 120, 121, 122, 483, 124, 125, 126, 127,\n",
       "       128, 482, 130, 481, 132, 133, 134, 135, 136, 137, 138, 139, 167,\n",
       "       170, 168, 212, 201, 202, 203, 204, 205, 476, 207, 208, 475, 474,\n",
       "       211, 213, 199, 214, 215, 216, 217, 218, 219, 220, 221, 222, 473,\n",
       "       472, 200, 198, 169, 182, 113, 171, 172, 173, 174, 175, 478, 177,\n",
       "       178, 179, 181, 184, 197, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "       193, 194, 196, 114, 485, 226, 111,  30,  31,  32,  33,  34,  35,\n",
       "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
       "       489,  50,  51,  52,  53,  54,  29,  28,  27,  13, 496, 495, 492,\n",
       "         5,   6,   7,   8, 491,  10,  11,  12,  14,  26,  15,  16,  17,\n",
       "        18,  19,  20,  21,  22,  23,  24, 490,  55,  56, 488,  98,  87,\n",
       "        88,  89, 486,  91,  92,  93,  94,  95,  96,  97,  99,  85, 100,\n",
       "       101, 102, 103, 104, 105, 106, 107, 108, 109, 110,  86,  84,  58,\n",
       "        70,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  71,\n",
       "        83,  72,  73,  74,  75,  76,  77,  78,  79, 487,  81,  82, 225,\n",
       "       227, 453, 397, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "       380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
       "       393, 395, 369, 368, 367, 353, 342, 463, 344, 345, 346, 347, 348,\n",
       "       349, 350, 351, 352, 354, 366, 355, 356, 357, 358, 359, 360, 361,\n",
       "       362, 363, 364, 365, 396, 398, 228, 399, 457, 429, 430, 431, 432,\n",
       "       433, 456, 435, 436, 437, 438, 455, 440, 441, 442, 443, 444, 445,\n",
       "       446, 447, 448, 449, 450, 451, 452, 427, 426, 425, 411, 400, 401,\n",
       "       459, 403, 404, 405, 406, 407, 408, 409, 410, 412, 424, 413, 414,\n",
       "       415, 416, 417, 458, 419, 420, 421, 422, 423, 341, 340, 464, 338,\n",
       "       257, 258, 259, 260, 261, 262, 469, 264, 265, 266, 267, 268, 269,\n",
       "       270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 256,\n",
       "       255, 254, 240, 229, 470, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "       239, 241, 253, 242, 243, 244, 245, 246, 247, 248, 498, 250, 251,\n",
       "       252, 282, 283, 284, 325, 314, 315, 316, 317, 318, 319, 320, 465,\n",
       "       322, 323, 324, 326, 312, 327, 328, 329, 330, 331, 332, 333, 334,\n",
       "       335, 336, 337, 313, 466, 285, 297, 286, 287, 288, 289, 290, 291,\n",
       "       468, 293, 294, 295, 296, 298, 310, 299, 300, 301, 302, 467, 304,\n",
       "       305, 306, 307, 308, 309, 249])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(lasso.coef_).argsort()[::-1] # Feature 5 only shows up in ~170th place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   1,   4,   3,   5, 439, 321, 224, 230, 428, 129, 494,\n",
       "       434, 105,  25, 209, 343, 339,  60, 303, 176, 112, 480,  57, 210,\n",
       "       123,  83, 449,  32, 402, 471, 143, 393, 409, 206, 386,  90, 472,\n",
       "       311, 462, 270, 195, 427, 380, 170, 436, 141, 499, 497, 285, 280,\n",
       "       310, 484,  80, 479, 418,  53, 131, 153, 265, 347, 263, 104, 451,\n",
       "       275, 271,  41, 160, 490, 154, 151, 152, 150, 119, 122, 157, 155,\n",
       "       156, 148, 158, 159, 118, 161, 162, 163, 149, 145, 147, 135, 124,\n",
       "       125, 126, 127, 128, 482, 130, 132, 133, 134, 136, 146, 121, 137,\n",
       "       138, 139, 140, 481, 142, 120, 144, 483, 164, 169, 165, 205, 194,\n",
       "       476, 196, 197, 198, 199, 200, 201, 202, 203, 204, 475, 166, 207,\n",
       "       208, 474, 473, 211, 212, 213, 214, 215, 216, 217, 193, 192, 191,\n",
       "       190, 167, 168, 116, 478, 171, 172, 173, 174, 175, 477, 177, 178,\n",
       "       179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 117, 450,\n",
       "       115,  43,  30,  31,  33,  34,  35,  36,  37,  38,  39,  40,  42,\n",
       "        44,  28,  45,  46,  47,  48,  49,  50,  51,  52,  54,  55,  56,\n",
       "        29,  27, 114,  13, 496, 495, 493, 492,   6,   7,   8,   9,  10,\n",
       "        11,  12,  14,  26,  15,  16,  17,  18,  19,  20,  21,  22,  23,\n",
       "        24, 491, 489,  58,  59, 100,  89, 486,  91,  92,  93,  94,  95,\n",
       "        96,  97,  98,  99, 101, 488, 102, 103, 485, 106, 107, 108, 109,\n",
       "       110, 111, 219, 113,  88,  87,  86,  85,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  81,  82, 487,  84, 218, 225, 220, 461, 369, 370, 371, 372,\n",
       "       373, 374, 375, 376, 377, 378, 379, 381, 367, 382, 383, 384, 385,\n",
       "       460, 387, 388, 389, 390, 391, 392, 368, 366, 221, 352, 340, 341,\n",
       "       342, 463, 344, 345, 346, 348, 349, 350, 351, 353, 365, 354, 355,\n",
       "       356, 357, 358, 359, 360, 361, 362, 363, 364, 459, 394, 395, 453,\n",
       "       425, 426, 456, 455, 429, 430, 431, 432, 433, 454, 435, 437, 396,\n",
       "       438, 452, 440, 441, 442, 443, 444, 445, 446, 447, 448, 424, 423,\n",
       "       422, 421, 397, 398, 399, 400, 401, 458, 403, 404, 405, 406, 407,\n",
       "       408, 457, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 464,\n",
       "       338, 337, 261, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 262, 279, 264, 266, 267, 268, 269, 468, 272, 273, 274, 276,\n",
       "       277, 498, 248, 247, 246, 222, 223, 470, 226, 227, 228, 229, 469,\n",
       "       231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243,\n",
       "       244, 245, 278, 281, 336, 323, 312, 313, 314, 315, 316, 317, 318,\n",
       "       319, 320, 465, 322, 324, 282, 325, 326, 327, 328, 329, 330, 331,\n",
       "       332, 333, 334, 335, 466, 309, 308, 307, 283, 284, 286, 287, 288,\n",
       "       289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301,\n",
       "       302, 467, 304, 305, 306, 249])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(rgs1.coef_).argsort()[::-1] # Feature 5 shows up in 6th place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare total number of feature subsets at step k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgs1</th>\n",
       "      <th>rgs2</th>\n",
       "      <th>rgs3</th>\n",
       "      <th>rgs4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>4995</td>\n",
       "      <td>1000</td>\n",
       "      <td>2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>4986</td>\n",
       "      <td>1000</td>\n",
       "      <td>2491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>4915</td>\n",
       "      <td>1000</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>4771</td>\n",
       "      <td>1000</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>4509</td>\n",
       "      <td>1000</td>\n",
       "      <td>2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>4199</td>\n",
       "      <td>1000</td>\n",
       "      <td>2356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>3763</td>\n",
       "      <td>1000</td>\n",
       "      <td>2335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>3348</td>\n",
       "      <td>1000</td>\n",
       "      <td>2315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rgs1  rgs2  rgs3  rgs4\n",
       "0  1000  5000  1000  2500\n",
       "1  1000  5000  1000  2500\n",
       "2  1000  4995  1000  2499\n",
       "3  1000  4986  1000  2491\n",
       "4  1000  4915  1000  2475\n",
       "5  1000  4771  1000  2431\n",
       "6  1000  4509  1000  2406\n",
       "7  1000  4199  1000  2356\n",
       "8  1000  3763  1000  2335\n",
       "9  1000  3348  1000  2315"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_subsets = {}\n",
    "for name, estimator in estimators.items():\n",
    "    if name not in [\"lasso\", \"rgs\"]:\n",
    "        n_subsets[name] = [sum(estimator.trajectory[j].values()) for j in range(10)]\n",
    "pd.DataFrame(n_subsets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
